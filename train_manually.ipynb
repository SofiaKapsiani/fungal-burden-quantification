{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd876344",
   "metadata": {},
   "source": [
    "Code for training U-Net model, adapted from GitHub repository: \n",
    "\"https://github.com/milesial/Pytorch-UNet\"                   \n",
    "Identical to train.py file but compatible with jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-brisbane",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from eval import eval_net\n",
    "from unet import UNet\n",
    "\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from utils.dataset import BasicDataset\n",
    "from utils.augmentations import AugDataset\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forbidden-wheat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify directories for images, masks, checkpoints and cross-validation data\n",
    "dir_img = './data/train/imgs/'\n",
    "dir_mask = './data/train/masks/'\n",
    "dir_checkpoint = './checkpoints/'\n",
    "dir_cv ='./cv/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "critical-requirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funtion for training the NN\n",
    "def train_net(net, device, dataset, train_set, val_set, fold = 0,  epochs=5, batch_size=1, \n",
    "              lr=0.0001, save_cp=True, img_scale=0.5, data_aug = 5):\n",
    "    \n",
    "    # track number of batches passed through the network\n",
    "    global_step = 0\n",
    "    # function will output txt file with the performance of the model on each epoch and fold\n",
    "    out_txt.write(f'Fold {fold +1} \\n') # write fold number in file\n",
    "    \n",
    "    # Define data loaders for training and validation set in this fold\n",
    "    train_loader = DataLoader(AugDataset(train_set,num = data_aug), batch_size=batch_size, pin_memory=True, num_workers=0)\n",
    "    val_loader = DataLoader(AugDataset(val_set, transform=None), batch_size=batch_size, pin_memory=True, num_workers=0)\n",
    "\n",
    "    # initialize optimizer\n",
    "    optimizer = optim.RMSprop(net.parameters(), lr=lr, weight_decay=1e-8, momentum=0.9)\n",
    "    # learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min' if net.n_classes > 1 else 'max', patience=2)\n",
    "    if net.n_classes > 1:\n",
    "        criterion = nn.CrossEntropyLoss() # use CrossEntropyLoss for multi-class segmentation\n",
    "    else:\n",
    "        criterion = nn.BCEWithLogitsLoss() # use BCEWithLogitsLoss for binary segmentation\n",
    "\n",
    "    # run the training loop for defined number of epochs\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        net.train()\n",
    "\n",
    "        # set initial loss value\n",
    "        epoch_loss = 0\n",
    "        # display epoch information and initiate training progress bar\n",
    "        with tqdm(total=len(train_loader.dataset), desc=f'Fold {fold +1}, Epoch {epoch + 1}/{epochs}', unit='img') as pbar:\n",
    "            # iterate over the DataLoader with training data\n",
    "            for batch in train_loader:\n",
    "                # define images and masks\n",
    "                imgs = batch['image']\n",
    "                true_masks = batch['mask']\n",
    "                # ensure that number of channels in input images are the same as the defined number of channels\n",
    "                assert imgs.shape[1] == net.n_channels, \\\n",
    "                    f'Network has been defined with {net.n_channels} input channels, ' \\\n",
    "                    f'but loaded images have {imgs.shape[1]} channels. Please check that ' \\\n",
    "                    'the images are loaded correctly.'\n",
    "                imgs = imgs.to(device=device, dtype=torch.float32)\n",
    "                mask_type = torch.float32 if net.n_classes == 1 else torch.long\n",
    "                true_masks = true_masks.to(device=device, dtype=mask_type)\n",
    "\n",
    "                # perform forward pass\n",
    "                masks_pred = net(imgs)\n",
    "\n",
    "                # compute loss\n",
    "                loss = criterion(masks_pred, true_masks)\n",
    "                # update loss\n",
    "                epoch_loss += loss.item()\n",
    "                # save loss to summary\n",
    "                writer.add_scalar('Loss/train', loss.item(), global_step)\n",
    "                # display loss\n",
    "                pbar.set_postfix(**{'loss (batch)': loss.item()})\n",
    "\n",
    "                # zero the gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # perform backward pass\n",
    "                loss.backward()\n",
    "                # gradient clipping\n",
    "                nn.utils.clip_grad_value_(net.parameters(), 0.1)\n",
    "                # perform optimization\n",
    "                optimizer.step()\n",
    "                \n",
    "                # update progress bar based on how many images have passed through the model\n",
    "                pbar.update(imgs.shape[0])\n",
    "                global_step += 1\n",
    "                # save weights and biases to summary\n",
    "                if global_step % (len(train_loader.dataset) // (10 * batch_size)) == 0:\n",
    "                    for tag, value in net.named_parameters():\n",
    "                        tag = tag.replace('.', '/')\n",
    "                        writer.add_histogram('weights/' + tag, value.data.cpu().numpy(), global_step)\n",
    "                        writer.add_histogram('grads/' + tag, value.grad.data.cpu().numpy(), global_step)\n",
    "                    # evaluate model\n",
    "                    val_score = eval_net(net, val_loader, device)\n",
    "                    # decay learning rate\n",
    "                    scheduler.step(val_score)\n",
    "                    # save learning rate to summary\n",
    "                    writer.add_scalar('learning_rate', optimizer.param_groups[0]['lr'], global_step)\n",
    "\n",
    "                    # print validation cross entropy or Dice coefficient depending on mask classes\n",
    "                    if net.n_classes > 1:\n",
    "                        logging.info('Validation cross entropy: {}'.format(val_score))\n",
    "                        writer.add_scalar('Loss/test', val_score, global_step) # save loss\n",
    "                    else:\n",
    "                        logging.info('Validation Dice Coeff: {}'.format(val_score))\n",
    "                        writer.add_scalar('Dice/test', val_score, global_step) # save loss\n",
    "                    \n",
    "                    # add batch image data to summary\n",
    "                    writer.add_images('images', imgs, global_step)\n",
    "                    if net.n_classes == 1:\n",
    "                        writer.add_images('masks/true', true_masks, global_step)\n",
    "                        writer.add_images('masks/pred', torch.sigmoid(masks_pred) > 0.5, global_step)\n",
    "        \n",
    "        # save checkpoint details\n",
    "        if save_cp:\n",
    "            try:\n",
    "                # create checkpoint directory if there isn't one\n",
    "                os.mkdir(dir_checkpoint)\n",
    "                logging.info('Created checkpoint directory')\n",
    "            except OSError:\n",
    "                pass\n",
    "            # name checkpoint file\n",
    "            torch.save(net.state_dict(),\n",
    "                       dir_checkpoint + f'CP_fold{fold +1}_epoch{epoch + 1}.pth')\n",
    "            logging.info(f'Checkpoint {epoch + 1}, fold {fold +1} saved !')\n",
    "        \n",
    "        # write dice score of each epoch in output txt file  \n",
    "        out_txt.write(f'Epoch{epoch +1}: Dice Coeff {val_score} \\n')\n",
    "    # write dice scores of next fold in a new line\n",
    "    out_txt.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-lancaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass arguments\n",
    "class empty: pass\n",
    "args = empty()\n",
    "# number of epochs\n",
    "args.epochs = 5\n",
    "# load model from a .pth file\n",
    "args.load = False\n",
    "# batch size\n",
    "args.batch_size = 1 # batch size was set to 1 as training images had slightly different dimentions\n",
    "# learning rate\n",
    "args.lr = 0.0001\n",
    "# image scale\n",
    "args.img_scale = 0.5\n",
    "# number of folds in k-fold cross-validation\n",
    "args.k_folds = 5\n",
    "# number of augmented images generated for each image in the train set\n",
    "args.data_aug = 2\n",
    "# whether checkpoint will be saved\n",
    "args.save_cp= True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-kazakhstan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise logging INFO, for displaying training information\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "# set device to cuda if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# display device used\n",
    "logging.info(f'Using device {device}')\n",
    "\n",
    "# convert images and masks into tensors\n",
    "dataset = BasicDataset(dir_img, dir_mask, args.img_scale)\n",
    "\n",
    "# writer will output to ./runs/ directory by default\n",
    "writer = SummaryWriter(comment=f'LR_{args.lr}_BS_{args.batch_size}_SCALE_{args.img_scale}')\n",
    "# print summary of input parameters\n",
    "logging.info(f'''Starting training:\n",
    "    Epochs:          {args.epochs}\n",
    "    Batch size:      {args.batch_size}\n",
    "    Learning rate:   {args.lr}\n",
    "    Training size:   {len(dataset)}\n",
    "    K-folds:         {args.k_folds}\n",
    "    Checkpoints:     {args.save_cp}\n",
    "    Device:          {device.type}\n",
    "    Images scaling:  {args.img_scale}\n",
    "    Data augmentations per image: {args.data_aug}\n",
    "''')\n",
    "\n",
    "\n",
    "# define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=args.k_folds, shuffle=False)\n",
    "\n",
    "# create txt file to save cross-validation data (variable named out_txt)\n",
    "try:\n",
    "    os.mkdir(dir_cv) # create directory for saving the cross-validation output txt file\n",
    "except OSError:\n",
    "    pass  \n",
    "# create and name output txt file \n",
    "out_txt= open(dir_cv + f'{now.strftime(\"%b-%d-%Y_%H-%M-%S\")}_LR_{args.lr}_BS_{args.batch_size}_SCALE_{args.img_scale}.txt', 'w')\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
    "\n",
    "    # display fold number\n",
    "    logging.info(f'''FOLD {fold +1}''')\n",
    "    \n",
    "    # initialise U-Net model and define number of channels, number of classes and up-scaling technique\n",
    "    net = UNet(n_channels=3, n_classes=1, bilinear=True)\n",
    "    \n",
    "    # if bilinear interpolation not indicated use transposed conv. up-scaling \n",
    "    logging.info(f'Network:\\n'\n",
    "                 f'\\t{net.n_channels} input channels\\n'\n",
    "                 f'\\t{net.n_classes} output channels (classes)\\n'\n",
    "                 f'\\t{\"Bilinear\" if net.bilinear else \"Transposed conv\"} upscaling')\n",
    " \n",
    "    net.to(device=device)\n",
    "    \n",
    "    \n",
    "    # Dividing data into folds\n",
    "    train_set = torch.utils.data.dataset.Subset(dataset,train_idx)\n",
    "    val_set = torch.utils.data.dataset.Subset(dataset,val_idx)\n",
    "    \n",
    "    # train model\n",
    "    try:\n",
    "        train_net(net=net,\n",
    "                  dataset = dataset,\n",
    "                  train_set = train_set,\n",
    "                  val_set = val_set,\n",
    "                  fold = fold,\n",
    "                  epochs=args.epochs,\n",
    "                  batch_size=args.batch_size,\n",
    "                  lr=args.lr,\n",
    "                  device=device,\n",
    "                  img_scale=args.img_scale,\n",
    "                  data_aug=args.data_aug,)\n",
    "    \n",
    "    # close checkpoint file and output txt if training interrupted \n",
    "    except KeyboardInterrupt:\n",
    "        torch.save(net.state_dict(), 'INTERRUPTED.pth')\n",
    "        logging.info('Saved interrupt')\n",
    "        out_txt.close()\n",
    "        try:\n",
    "            sys.exit(0)\n",
    "        except SystemExit:\n",
    "            os._exit(0)\n",
    "            \n",
    "# close checkpoint file and output txt when training is completed           \n",
    "out_txt.close()\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
